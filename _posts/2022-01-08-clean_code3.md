---
layout: post
title: code_clean3
categories: kaggle, tensorflow, python
tags: python
published: true	
---

```python

# !nvidia-smi

import tensorflow as tf
device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
    raise SystemError("GPU device not found")
print("Found GPU at: {}".format(device_name))

import cv2, imageio
import numpy as np
from scipy import ndimage
from glob import glob 

train_img_paths = sorted(glob('/content/drive/MyDrive/Seg_Data/image/*.jpg'))
train_mask_paths = sorted(glob('/content/drive/MyDrive/Seg_Data/mask/*.png'))

train_imgs = np.array([cv2.resize(cv2.imread(path, cv2.IMREAD_UNCHANGED), (512,512)) for path in train_img_paths])

train_masks = np.array([cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE), (512,512)) for path in train_mask_paths])

train_masks = train_masks.astype(np.float32)
train_masks = np.reshape(train_masks, (*train_masks.shape, 1))

train_masks -= 1

# %matplotlib inline
from matplotlib import pyplot as plt
fig = plt.figure(0, figsize=(20, 20))
fig.add_subplot(1, 2, 1)
plt.imshow(train_imgs[0])
fig.add_subplot(1, 2, 2)
plt.imshow(np.squeeze(train_masks[0]), cmap='gray')

from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, BatchNormalization, concatenate
from keras.models import Model

from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, BatchNormalization, concatenate
from keras.models import Model


inputs = Input((512, 512, 3))
bnorm1 = BatchNormalization()(inputs)
conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(bnorm1)
conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)
pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)

conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)
conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)
pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)

conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)
conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)
pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)

conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)
conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)
pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)

conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)
conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)

up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)
conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)
conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)

up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)
conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)
conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)

up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)
conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)
conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)

up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)
conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)
conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)

conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)

model = Model(inputs=[inputs], outputs=[conv10])

from keras import backend as K
from keras.losses import binary_crossentropy

SMOOTH = 1.

def dice_coef(y_true, y_pred):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (2. * intersection + SMOOTH) / (K.sum(y_true_f) + K.sum(y_pred_f) + SMOOTH)

def bce_dice_loss(y_true, y_pred):
    return 0.5 * binary_crossentropy(y_true, y_pred) - dice_coef(y_true, y_pred)

from tensorflow.keras.optimizers import Adam
model.compile(Adam(learning_rate=1e-4), bce_dice_loss, metrics=[binary_crossentropy, dice_coef])

model.fit(train_imgs[50:], train_masks[50:], batch_size=12, epochs=10, validation_data=(train_imgs[:50], train_masks[:50]))

pred_img = model.predict(train_imgs)
# 한 데이터셋만 넣고 싶을 경우에는 slicing한다. train_imgs[:1]
# 결과가 (row, col, 1) 일 경우, plt 영상이 안 보일경우 np.squeeze(img)를 처리한다.

temp_pred = []

for elem in pred_img:
    bgr_img = cv2.cvtColor(elem, cv2.COLOR_GRAY2RGB)
    temp_pred.append(bgr_img)

for img_ in temp_pred:
    plt.imshow(img_)
    plt.show()

temp_2_pred = []

for elem in temp_pred:
    elem[elem<0.5] = 0
    elem[elem>=0.5] = 1
    elem.astype('uint8')
    temp_2_pred.append(elem)


for i, elem in enumerate(temp_2_pred):
    path = '/content/drive/MyDrive/Seg_Data/result/result_%03d.png'%(i+1)
    cv2.imwrite(path, elem)



bg = np.zeros_like(train_imgs[0])

original_img = train_imgs[0]

ret, thresh = cv2.threshold(temp_img, 127, 255, 0)

contour2, h_ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)


for cnt in contour2:
    cv2.drawContours(bg, [cnt], 0, (0, 255, 0), -1)

masked = cv2.bitwise_and(original_img, bg)
```
